{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11463852,"sourceType":"datasetVersion","datasetId":7183638}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:38.608572Z","iopub.execute_input":"2025-04-20T11:58:38.608855Z","iopub.status.idle":"2025-04-20T11:58:39.634759Z","shell.execute_reply.started":"2025-04-20T11:58:38.608830Z","shell.execute_reply":"2025-04-20T11:58:39.634012Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"submission_df = pd.read_csv('/kaggle/input/document-summarization-llms/submission_format.csv')\ntest_df = pd.read_csv('/kaggle/input/document-summarization-llms/test_features.csv')\ntrain_df = pd.read_csv('/kaggle/input/document-summarization-llms/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:39.635968Z","iopub.execute_input":"2025-04-20T11:58:39.636330Z","iopub.status.idle":"2025-04-20T11:58:41.007908Z","shell.execute_reply.started":"2025-04-20T11:58:39.636304Z","shell.execute_reply":"2025-04-20T11:58:41.007365Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.008634Z","iopub.execute_input":"2025-04-20T11:58:41.008930Z","iopub.status.idle":"2025-04-20T11:58:41.029000Z","shell.execute_reply.started":"2025-04-20T11:58:41.008905Z","shell.execute_reply":"2025-04-20T11:58:41.028361Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   paper_id                   summary\n0      1000  my very accurate summary\n1      1001  my very accurate summary\n2      1002  my very accurate summary\n3      1003  my very accurate summary\n4      1004  my very accurate summary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>my very accurate summary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>my very accurate summary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>my very accurate summary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>my very accurate summary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1004</td>\n      <td>my very accurate summary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.030661Z","iopub.execute_input":"2025-04-20T11:58:41.030860Z","iopub.status.idle":"2025-04-20T11:58:41.039555Z","shell.execute_reply.started":"2025-04-20T11:58:41.030844Z","shell.execute_reply":"2025-04-20T11:58:41.038978Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   paper_id                                               text  \\\n0         0  ## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...   \n1         1  ## 1. Introduction\\n\\n\\nAn Electronic Health R...   \n2         2  ## Introduction\\n\\n\\nTranslation  plays  an  i...   \n3         3  ## 1 Problem Setup\\n\\n\\nRecent political scien...   \n4         4  ## INTRODUCTION\\n\\n\\nThis  article  investigat...   \n\n                                             summary  \n0  In this article, Victor Fan argues that analys...  \n1  Problem definition: Physicians spend more than...  \n2  Literary translation is one of the most challe...  \n3  There is a long-running debate on evaluating f...  \n4  Recently, ‘bimajyo’ (美魔女) came into focus in J...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...</td>\n      <td>In this article, Victor Fan argues that analys...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>## 1. Introduction\\n\\n\\nAn Electronic Health R...</td>\n      <td>Problem definition: Physicians spend more than...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>## Introduction\\n\\n\\nTranslation  plays  an  i...</td>\n      <td>Literary translation is one of the most challe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>## 1 Problem Setup\\n\\n\\nRecent political scien...</td>\n      <td>There is a long-running debate on evaluating f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>## INTRODUCTION\\n\\n\\nThis  article  investigat...</td>\n      <td>Recently, ‘bimajyo’ (美魔女) came into focus in J...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df.text[0][:1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.040341Z","iopub.execute_input":"2025-04-20T11:58:41.040791Z","iopub.status.idle":"2025-04-20T11:58:41.053319Z","shell.execute_reply.started":"2025-04-20T11:58:41.040767Z","shell.execute_reply":"2025-04-20T11:58:41.052735Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCIOUSNESS\\n\\n\\nSince 1997, the concept of extraterritoriality has been configured in the political tension between Hong Kong and Beijing. From the perspective of the Central Government, it is fundamental for the people of China to shijian zhuquan instantiate its sovereignty over Hong Kong. But while most Hong / Kong residents insist on interpreting this concept in terms of the Euro-American notion of selfdetermination  (zizhu / making decisions  for  oneself),  the  Beijing  government  believes  that  the Hong Kong legislature must make decisions in conformation to the larger will of the people, which the Party represents, a concept taken from the writings of Lenin and Stalin (Gao 2010: 26-30). This tension is crystalised in the long debate about Article 23 of the Hong Kong Basic Law, which requires  the  SAR  to  'enact  laws  on  its  own  to  prohibit  any  act  of  treason,  secession,  sedition, subversion  against  the  Central  People's \""},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_df.summary[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.053999Z","iopub.execute_input":"2025-04-20T11:58:41.054209Z","iopub.status.idle":"2025-04-20T11:58:41.066199Z","shell.execute_reply.started":"2025-04-20T11:58:41.054192Z","shell.execute_reply":"2025-04-20T11:58:41.065622Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'In this article, Victor Fan argues that analysing contemporary Hong Kong cinema requires active rewriting of established postcolonial theories by taking into account the specific mode of colonisation of Hong Kong: extraterritoriality. This concept has been responsible for the construction of the cultural plurality, linguistic ambiguity, and political liminality of Hong Kong and its cinematographic experience, as well as the incongruence between the community’s political consciousness after 1997 and the larger national imagination promulgated by the Beijing government. The term ‘extraterritoriality’ was translated into Chinese after 1895 via Japanese as zhiwai faquan the right to exercise one’s law outside a nation state’s sovereign terrain, and colonialism in China between 1844 and 1949 was largely characterized by a continuous reformulation and systematisation of this concept. It in fact still informs the way former colonised regions in China are administered today, and the political unconscious of their residents. With Jonnie To’s 2012 film Duzhan (Dukzin) /Drug War as a case study, contemporary Hong Kong cinema, Fan argues, can be understood as a public sphere where an extraterritorial consciousness and the contesting political affects associated with it are actively negotiated.'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.066803Z","iopub.execute_input":"2025-04-20T11:58:41.066964Z","iopub.status.idle":"2025-04-20T11:58:41.080225Z","shell.execute_reply.started":"2025-04-20T11:58:41.066950Z","shell.execute_reply":"2025-04-20T11:58:41.079655Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   paper_id                                               text\n0      1000  ## Introduction\\n\\n\\nGender disparities persis...\n1      1001  ## Introduction\\n\\n\\nOne of humanity’s greates...\n2      1002  ## Introduction\\n\\n\\nHow do workers get attach...\n3      1003  ## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...\n4      1004  ## The Evolution of Environmental and Climate ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>## Introduction\\n\\n\\nGender disparities persis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>## Introduction\\n\\n\\nOne of humanity’s greates...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>## Introduction\\n\\n\\nHow do workers get attach...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1004</td>\n      <td>## The Evolution of Environmental and Climate ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"len(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.081198Z","iopub.execute_input":"2025-04-20T11:58:41.081535Z","iopub.status.idle":"2025-04-20T11:58:41.092129Z","shell.execute_reply.started":"2025-04-20T11:58:41.081500Z","shell.execute_reply":"2025-04-20T11:58:41.091570Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"len(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.092708Z","iopub.execute_input":"2025-04-20T11:58:41.092872Z","iopub.status.idle":"2025-04-20T11:58:41.105250Z","shell.execute_reply.started":"2025-04-20T11:58:41.092858Z","shell.execute_reply":"2025-04-20T11:58:41.104570Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"345"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"%%capture\n!pip install transformers rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:58:41.107218Z","iopub.execute_input":"2025-04-20T11:58:41.107414Z","iopub.status.idle":"2025-04-20T11:58:47.040346Z","shell.execute_reply.started":"2025-04-20T11:58:41.107399Z","shell.execute_reply":"2025-04-20T11:58:47.039362Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom rouge_score import rouge_scorer\nimport markdown\nimport torch\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:59:48.027554Z","iopub.execute_input":"2025-04-20T11:59:48.027828Z","iopub.status.idle":"2025-04-20T11:59:48.031922Z","shell.execute_reply.started":"2025-04-20T11:59:48.027809Z","shell.execute_reply":"2025-04-20T11:59:48.031133Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:59:48.467207Z","iopub.execute_input":"2025-04-20T11:59:48.467481Z","iopub.status.idle":"2025-04-20T11:59:48.471831Z","shell.execute_reply.started":"2025-04-20T11:59:48.467461Z","shell.execute_reply":"2025-04-20T11:59:48.471120Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration, get_linear_schedule_with_warmup\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.optim import AdamW\nimport torch.nn as nn\nimport numpy as np\nimport time\nimport datetime\nimport torch\n\n# Custom Dataset class\nclass SummaryDataset(Dataset):\n    def __init__(self, texts, summaries, tokenizer, max_length=1024):\n        self.texts = texts\n        self.summaries = summaries\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        summary = str(self.summaries[idx])\n        \n        text_encoding = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        summary_encoding = self.tokenizer(\n            summary,\n            max_length=150,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        labels = summary_encoding['input_ids']\n        labels[labels == self.tokenizer.pad_token_id] = -100\n        \n        return {\n            'input_ids': text_encoding['input_ids'].flatten(),\n            'attention_mask': text_encoding['attention_mask'].flatten(),\n            'labels': labels.flatten()\n        }\n\n# Initialize tokenizer and model\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n\n# Create dataset and split into train/val\ndataset = SummaryDataset(train_df['text'].values, train_df['summary'].values, tokenizer)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create data loaders\nbatch_size = 4  # Reduce batch size if you get CUDA out of memory\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n# Training setup\nepochs = 24\noptimizer = AdamW(model.parameters(), lr=3e-5)\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)\n\n# Early stopping setup\nearly_stopping_patience = 3\nearly_stopping_counter = 0\nbest_val_loss = float('inf')\n\n# Training loop\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    print('-' * 10)\n    \n    # Training\n    model.train()\n    total_train_loss = 0\n    \n    for batch in tqdm(train_loader, desc=\"Training\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        \n        loss = outputs.loss\n        total_train_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    print(f'Training loss: {avg_train_loss}')\n    \n    # Validation\n    model.eval()\n    total_val_loss = 0\n    \n    for batch in tqdm(val_loader, desc=\"Validation\"):\n        with torch.no_grad():\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            loss = outputs.loss\n            total_val_loss += loss.item()\n    \n    avg_val_loss = total_val_loss / len(val_loader)\n    print(f'Validation loss: {avg_val_loss}')\n    \n    # Early stopping check\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        early_stopping_counter = 0\n        # Save the best model\n        torch.save(model.state_dict(), 'best_model.pt')\n        print(\"Saved best model\")\n    else:\n        early_stopping_counter += 1\n        print(f\"Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n        if early_stopping_counter >= early_stopping_patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Load the best model\nmodel.load_state_dict(torch.load('best_model.pt'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:59:52.343637Z","iopub.execute_input":"2025-04-20T11:59:52.344204Z","iopub.status.idle":"2025-04-20T12:18:19.624920Z","shell.execute_reply.started":"2025-04-20T11:59:52.344183Z","shell.execute_reply":"2025-04-20T12:18:19.624137Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c19f5470e14038a3bd124318d645f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98cb157c0684614a935bec39d16ffed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a243d89a10a4c30b64811bd40ae7c85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae7a9a9dff94059af571dda5ee0709f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f80a547d76d14d1281fe893fe30a85a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4323dcfa794e8c8a63ccaef953a63d"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/24\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 200/200 [04:04<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 2.7905342614650728\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 50/50 [00:28<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 2.5261825799942015\nSaved best model\nEpoch 2/24\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 200/200 [04:03<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 2.2231368523836137\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 50/50 [00:27<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 2.538730778694153\nEarly stopping counter: 1/3\nEpoch 3/24\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 200/200 [04:04<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 1.7938468545675277\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 50/50 [00:27<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 2.6490711092948915\nEarly stopping counter: 2/3\nEpoch 4/24\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 200/200 [04:04<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 1.421841774880886\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 50/50 [00:27<00:00,  1.81it/s]\n/tmp/ipykernel_31/1730706470.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model.pt'))\n","output_type":"stream"},{"name":"stdout","text":"Validation loss: 2.815855100154877\nEarly stopping counter: 3/3\nEarly stopping triggered\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Function to generate summary\ndef generate_summary(text):\n    inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, \n                               length_penalty=2.0, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n\n# Generate summaries for test set\ntest_summaries = [generate_summary(text) for text in tqdm(test_df['text'], desc=\"Generating summaries\")]\n\n# Prepare submission\nsubmission_df = pd.DataFrame({\n    'paper_id': test_df['paper_id'],\n    'summary': test_summaries\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:18:19.626260Z","iopub.execute_input":"2025-04-20T12:18:19.626790Z","iopub.status.idle":"2025-04-20T12:28:37.338242Z","shell.execute_reply.started":"2025-04-20T12:18:19.626768Z","shell.execute_reply":"2025-04-20T12:28:37.337582Z"}},"outputs":[{"name":"stderr","text":"Generating summaries: 100%|██████████| 345/345 [10:17<00:00,  1.79s/it]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Save to CSV\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:28:37.339016Z","iopub.execute_input":"2025-04-20T12:28:37.339700Z","iopub.status.idle":"2025-04-20T12:28:37.355780Z","shell.execute_reply.started":"2025-04-20T12:28:37.339674Z","shell.execute_reply":"2025-04-20T12:28:37.355237Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as 'submission.csv'\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:28:37.357350Z","iopub.execute_input":"2025-04-20T12:28:37.357675Z","iopub.status.idle":"2025-04-20T12:28:37.364619Z","shell.execute_reply.started":"2025-04-20T12:28:37.357660Z","shell.execute_reply":"2025-04-20T12:28:37.363936Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   paper_id                                            summary\n0      1000  Gender disparities persist in how men and wome...\n1      1001  Climate change mitigation cannot occur without...\n2      1002  Employee testimonials are personal narratives ...\n3      1003  Despite the importance of the concept of “comm...\n4      1004  This study explores how childbirth is associat...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paper_id</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>Gender disparities persist in how men and wome...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>Climate change mitigation cannot occur without...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>Employee testimonials are personal narratives ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>Despite the importance of the concept of “comm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1004</td>\n      <td>This study explores how childbirth is associat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"submission_df.summary[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:28:37.365306Z","iopub.execute_input":"2025-04-20T12:28:37.365545Z","iopub.status.idle":"2025-04-20T12:28:37.377524Z","shell.execute_reply.started":"2025-04-20T12:28:37.365528Z","shell.execute_reply":"2025-04-20T12:28:37.376972Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'Gender disparities persist in how men and women divide paid work, housework and childcare responsibilities. Despite rising levels of education and labor force participation among women, they continue to perform a larger portion of paid work and childcare compared to their male partners. This gendered division of labor remains prevalent, even as traditional views on gender roles have declined in postindustrial economies (Grunow et al., 2018). While women have increasingly entered the workforce in the past decades, this shift has not been met with a corresponding increase in men’s contribution to household tasks, particularly in childcare. Scholars have reviewed theoretical approaches to explain these continuing disparities. Using the concept of gender ideology as an analytical heuristic tool, we propose a theoretical model to explore support'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"import torch\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nfrom pathlib import Path\n\nclass SummaryGenerator:\n    def __init__(self, model_path=\"best_model.pt\"):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n        self.model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(self.device)\n        \n        # Load your trained weights\n        if Path(model_path).exists():\n            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n            print(f\"Loaded trained model weights from {model_path}\")\n        else:\n            print(\"Using pretrained weights (no fine-tuning)\")\n        \n        self.model.eval()\n    \n    def summarize(self, text, max_length=150, min_length=40):\n        \"\"\"\n        Generate a summary for the input text\n        \n        Args:\n            text (str): Input text to summarize\n            max_length (int): Maximum length of summary\n            min_length (int): Minimum length of summary\n            \n        Returns:\n            str: Generated summary\n        \"\"\"\n        inputs = self.tokenizer(\n            text,\n            max_length=1024,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        ).to(self.device)\n        \n        summary_ids = self.model.generate(\n            inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=max_length,\n            min_length=min_length,\n            length_penalty=2.0,\n            num_beams=4,\n            early_stopping=True\n        )\n        \n        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize the summarizer\n    summarizer = SummaryGenerator()\n    \n    # Example input text (replace with your own)\n    input_text = \"\"\"\n    Artificial intelligence (AI) is transforming industries across the globe. \n    From healthcare to finance, AI applications are enabling faster and more accurate decision-making. \n    In healthcare, AI algorithms can analyze medical images to detect diseases earlier than human doctors. \n    Financial institutions use AI for fraud detection and algorithmic trading. \n    Despite these advances, ethical concerns about AI bias and job displacement remain significant challenges.\n    \"\"\"\n    \n    # Generate and print the summary\n    summary = summarizer.summarize(input_text)\n    print(\"\\nGenerated Summary:\")\n    print(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:37:13.553141Z","iopub.execute_input":"2025-04-20T12:37:13.553716Z","iopub.status.idle":"2025-04-20T12:37:18.012913Z","shell.execute_reply.started":"2025-04-20T12:37:13.553687Z","shell.execute_reply":"2025-04-20T12:37:18.012139Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/826065813.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n","output_type":"stream"},{"name":"stdout","text":"Loaded trained model weights from best_model.pt\n\nGenerated Summary:\nArtificial intelligence (AI) is transforming industries across the globe. From healthcare to finance, AI applications are enabling faster and more accurate decision-making. Despite these advances, ethical concerns about AI bias and job displacement remain significant challenges.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}